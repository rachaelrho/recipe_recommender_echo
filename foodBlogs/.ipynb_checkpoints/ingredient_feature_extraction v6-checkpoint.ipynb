{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachaelrho/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "##text pre-processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "\n",
    "##feature extraction + similarity\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate json files and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatJson(file_list):\n",
    "    full = []\n",
    "    with open(\"allRecipes.json\", \"w\") as outfile:\n",
    "        for f in file_list:\n",
    "            with open(f, 'rb') as infile:\n",
    "                file_data = json.load(infile)\n",
    "                full += file_data\n",
    "        json.dump(full, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def openJson(name):\n",
    "    with open(name, 'rb') as infile:\n",
    "        full = json.load(infile)\n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = [\"fullhelping_items.json\", \"iLoveVegan_items.json\",\"MinimalistBaker_items.json\", \"ohsheglows_items.json\",\n",
    "             \"PaleOMG_items.json\",\"roastedRoot_items.json\",\"ohmyveggies_items.json\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concatJson(file_list)\n",
    "full = openJson('allRecipes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullDF = pd.DataFrame(full)\n",
    "fullDF1 = fullDF[(fullDF.ingredientsList.str.len() != 0)]\n",
    "recipeDF = fullDF1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipeDF.to_pickle('recipeDF_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recipeDF = pd.read_pickle('recipeDF_v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Write ingredients to file format for NYT ingredient tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nytIngredientInput(df):\n",
    "    f = open(\"input.txt\", \"a\")\n",
    "    ingredientList = []\n",
    "    for row in range(0,len(df)):\n",
    "        ingredients = df.ingredientsList.iloc[row]\n",
    "        for i in range(0,len(ingredients)):\n",
    "            line = ingredients[i].encode('ascii','ignore')\n",
    "            ingredientList.append([row,i,line])\n",
    "            f.write(line + ' /' + str(row) + ' ' + '\\n')\n",
    "    f.close()   \n",
    "    return ingredientList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredientList = nytIngredientInput(recipeDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredientDF = pd.DataFrame(ingredientList, columns=['recipeIndex','ingredientIndex','recipeText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipeDF.to_pickle('ingredientDF_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recipeDF = pd.read_pickle('ingredientDF_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge NYT ingredient tags with ingredientDF\n",
    "<p>(see NYT_CRF_IngredientPhraseTagger.txt for tags) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredientTags = openJson('results_6-21.json')\n",
    "ingredientTagsDF = pd.DataFrame(ingredientTags)\n",
    "ingredientTagsDF.to_pickle('ingredientTagsDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredientTaggedDF = pd.concat([ingredientDF,ingredientTagsDF], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mergedIndex(df):\n",
    "\n",
    "    df['mergedrecipeIndex'] = 'NA'\n",
    "\n",
    "    for i in range(0,len(df)): \n",
    "        try:\n",
    "            text = str(df.name.loc[i])\n",
    "            df.name.loc[i] = text.rsplit(' ', 1)[0]\n",
    "            df.mergedrecipeIndex.loc[i] = int(text.rsplit(' ', 1)[1])\n",
    "        except:\n",
    "            pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredientTaggedDF = mergedIndex(ingredientTaggedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredientTaggedDF.to_pickle('ingredientTaggedDF_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredientTaggedDF = pd.read_pickle('ingredientTaggedDF_v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Ingredient Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredientTaggedDF['name'] = ingredientTaggedDF['name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingredientTokens(df,taggeddf):\n",
    "    df['ingredientTokens'] = 0\n",
    "    for i in range(0,len(taggeddf.recipeIndex.unique())):\n",
    "        ingredients = taggeddf.name[taggeddf.recipeIndex == i]\n",
    "        df['ingredientTokens'][i] = str(' '.join(ingredients))  \n",
    "    df['ingredientTokens'] = df['ingredientTokens'].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nlpTokens(document):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    \n",
    "    tokens = [PorterStemmer().stem(x) for x in tokens]\n",
    "    tokens = [WordNetLemmatizer().lemmatize(x, 'v') for x in tokens]\n",
    "    \n",
    "    stop = stopwords.words('english')\n",
    "    tokens = [x for x in tokens if x not in stop] \n",
    "    return ','.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachaelrho/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "recipeDF = ingredientTokens(recipeDF,ingredientTaggedDF)\n",
    "recipeDF.loc[:, 'ingredientTokens'] = recipeDF.loc[:, 'ingredientTokens'].apply(nlpTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipeDF.to_pickle('recipeDF_tokens_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipeDF = pd.read_pickle('recipeDF_tokens_v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopList = ('tbsp','From')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tfidfVectorizer(stopList,df):\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=.2, max_features=1300, min_df=0.01, stop_words= stopList, use_idf=True, ngram_range=(1,3))\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df.ingredientTokens)\n",
    "    terms = sorted([(i,v) for v,i in tfidf_vectorizer.vocabulary_.items()])\n",
    "    vocab = [x[1] for x in terms]\n",
    "    \n",
    "    return tfidf_vectorizer,tfidf_matrix,terms,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer,tfidf_matrix,terms,vocab = tfidfVectorizer(['nan','tbsp','tsp',','],recipeDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, Sigma, VT = randomized_svd(tfidf_matrix, n_components=25,\n",
    "                                      n_iter=5,\n",
    "                                      random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.70401137,   9.22868086,   6.49565664,   6.27835743,\n",
       "         6.09854453,   5.69469634,   5.6498461 ,   5.48071641,\n",
       "         5.3851342 ,   5.31626579,   5.19163403,   5.03017515,\n",
       "         4.98309644,   4.91513431,   4.85479782,   4.69007801,\n",
       "         4.64749497,   4.62764541,   4.51477365,   4.42153623,\n",
       "         4.40361155,   4.27058744,   4.25877967,   4.17779088,   4.1084884 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NMFactorize(tfidf_matrix,n):\n",
    "    NMFmodel = NMF(n_components=n, init='random', random_state=0)\n",
    "    NMF_matrix = NMFmodel.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    return NMFmodel,NMF_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NMFmodel,NMF_matrix = NMFactorize(tfidf_matrix,15) ##chose 15 components since eigen vector largely falls under general food types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(NMFmodel, open( \"NMFmodel_v6.p\", \"wb\"))\n",
    "pickle.dump(NMF_matrix, open( \"NMFmatrix_v6.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
